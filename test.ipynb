{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated memory usage: 0.53 GB\n"
     ]
    }
   ],
   "source": [
    "# GPT-2 Small Specifications\n",
    "num_layers = 12\n",
    "num_heads = 12\n",
    "vocab_size = 55236\n",
    "hidden_dim = 768\n",
    "seq_length = 2048\n",
    "\n",
    "# Memory for token embeddings\n",
    "token_embeddings = vocab_size * hidden_dim * 4  # 4 bytes per float32\n",
    "\n",
    "# Memory for position embeddings\n",
    "position_embeddings = seq_length * hidden_dim * 4\n",
    "\n",
    "# Memory for layer parameters (assuming layer normalization, attention, and feedforward for each layer)\n",
    "layer_norm = 2 * hidden_dim * 4  # 2 for scale and bias\n",
    "attention = 4 * hidden_dim * hidden_dim * 4  # Query, Key, Value, and Output matrices\n",
    "feedforward = 4 * hidden_dim * hidden_dim * 4  # Two linear layers, typically 4x expansion\n",
    "layer_params = (layer_norm + attention + feedforward) * num_layers\n",
    "\n",
    "# Memory for attention cache\n",
    "attention_cache = num_layers * num_heads * seq_length * (hidden_dim // num_heads) * 2 * 4  # Key and Value states\n",
    "\n",
    "# Memory for activations (rough estimate, varies during inference)\n",
    "activations = seq_length * hidden_dim * 4 * 3  # Rough estimate for main activations\n",
    "\n",
    "# Total memory\n",
    "total_memory = token_embeddings + position_embeddings + layer_params + attention_cache + activations\n",
    "\n",
    "# Convert to GB\n",
    "total_memory_gb = total_memory / (1024**3)\n",
    "\n",
    "print(f\"Estimated memory usage: {total_memory_gb:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save in a format readable by c\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "data = torch.load('pytorch_model.bin', map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wte.weight torch.Size([50257, 768])\n",
      "wpe.weight torch.Size([1024, 768])\n",
      "h.0.ln_1.weight torch.Size([768])\n",
      "h.0.ln_1.bias torch.Size([768])\n",
      "h.0.attn.bias torch.Size([1, 1, 1024, 1024])\n",
      "h.0.attn.c_attn.weight torch.Size([768, 2304])\n",
      "h.0.attn.c_attn.bias torch.Size([2304])\n",
      "h.0.attn.c_proj.weight torch.Size([768, 768])\n",
      "h.0.attn.c_proj.bias torch.Size([768])\n",
      "h.0.ln_2.weight torch.Size([768])\n",
      "h.0.ln_2.bias torch.Size([768])\n",
      "h.0.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "h.0.mlp.c_fc.bias torch.Size([3072])\n",
      "h.0.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "h.0.mlp.c_proj.bias torch.Size([768])\n",
      "h.1.ln_1.weight torch.Size([768])\n",
      "h.1.ln_1.bias torch.Size([768])\n",
      "h.1.attn.bias torch.Size([1, 1, 1024, 1024])\n",
      "h.1.attn.c_attn.weight torch.Size([768, 2304])\n",
      "h.1.attn.c_attn.bias torch.Size([2304])\n",
      "h.1.attn.c_proj.weight torch.Size([768, 768])\n",
      "h.1.attn.c_proj.bias torch.Size([768])\n",
      "h.1.ln_2.weight torch.Size([768])\n",
      "h.1.ln_2.bias torch.Size([768])\n",
      "h.1.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "h.1.mlp.c_fc.bias torch.Size([3072])\n",
      "h.1.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "h.1.mlp.c_proj.bias torch.Size([768])\n",
      "h.2.ln_1.weight torch.Size([768])\n",
      "h.2.ln_1.bias torch.Size([768])\n",
      "h.2.attn.bias torch.Size([1, 1, 1024, 1024])\n",
      "h.2.attn.c_attn.weight torch.Size([768, 2304])\n",
      "h.2.attn.c_attn.bias torch.Size([2304])\n",
      "h.2.attn.c_proj.weight torch.Size([768, 768])\n",
      "h.2.attn.c_proj.bias torch.Size([768])\n",
      "h.2.ln_2.weight torch.Size([768])\n",
      "h.2.ln_2.bias torch.Size([768])\n",
      "h.2.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "h.2.mlp.c_fc.bias torch.Size([3072])\n",
      "h.2.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "h.2.mlp.c_proj.bias torch.Size([768])\n",
      "h.3.ln_1.weight torch.Size([768])\n",
      "h.3.ln_1.bias torch.Size([768])\n",
      "h.3.attn.bias torch.Size([1, 1, 1024, 1024])\n",
      "h.3.attn.c_attn.weight torch.Size([768, 2304])\n",
      "h.3.attn.c_attn.bias torch.Size([2304])\n",
      "h.3.attn.c_proj.weight torch.Size([768, 768])\n",
      "h.3.attn.c_proj.bias torch.Size([768])\n",
      "h.3.ln_2.weight torch.Size([768])\n",
      "h.3.ln_2.bias torch.Size([768])\n",
      "h.3.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "h.3.mlp.c_fc.bias torch.Size([3072])\n",
      "h.3.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "h.3.mlp.c_proj.bias torch.Size([768])\n",
      "h.4.ln_1.weight torch.Size([768])\n",
      "h.4.ln_1.bias torch.Size([768])\n",
      "h.4.attn.bias torch.Size([1, 1, 1024, 1024])\n",
      "h.4.attn.c_attn.weight torch.Size([768, 2304])\n",
      "h.4.attn.c_attn.bias torch.Size([2304])\n",
      "h.4.attn.c_proj.weight torch.Size([768, 768])\n",
      "h.4.attn.c_proj.bias torch.Size([768])\n",
      "h.4.ln_2.weight torch.Size([768])\n",
      "h.4.ln_2.bias torch.Size([768])\n",
      "h.4.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "h.4.mlp.c_fc.bias torch.Size([3072])\n",
      "h.4.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "h.4.mlp.c_proj.bias torch.Size([768])\n",
      "h.5.ln_1.weight torch.Size([768])\n",
      "h.5.ln_1.bias torch.Size([768])\n",
      "h.5.attn.bias torch.Size([1, 1, 1024, 1024])\n",
      "h.5.attn.c_attn.weight torch.Size([768, 2304])\n",
      "h.5.attn.c_attn.bias torch.Size([2304])\n",
      "h.5.attn.c_proj.weight torch.Size([768, 768])\n",
      "h.5.attn.c_proj.bias torch.Size([768])\n",
      "h.5.ln_2.weight torch.Size([768])\n",
      "h.5.ln_2.bias torch.Size([768])\n",
      "h.5.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "h.5.mlp.c_fc.bias torch.Size([3072])\n",
      "h.5.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "h.5.mlp.c_proj.bias torch.Size([768])\n",
      "h.6.ln_1.weight torch.Size([768])\n",
      "h.6.ln_1.bias torch.Size([768])\n",
      "h.6.attn.bias torch.Size([1, 1, 1024, 1024])\n",
      "h.6.attn.c_attn.weight torch.Size([768, 2304])\n",
      "h.6.attn.c_attn.bias torch.Size([2304])\n",
      "h.6.attn.c_proj.weight torch.Size([768, 768])\n",
      "h.6.attn.c_proj.bias torch.Size([768])\n",
      "h.6.ln_2.weight torch.Size([768])\n",
      "h.6.ln_2.bias torch.Size([768])\n",
      "h.6.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "h.6.mlp.c_fc.bias torch.Size([3072])\n",
      "h.6.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "h.6.mlp.c_proj.bias torch.Size([768])\n",
      "h.7.ln_1.weight torch.Size([768])\n",
      "h.7.ln_1.bias torch.Size([768])\n",
      "h.7.attn.bias torch.Size([1, 1, 1024, 1024])\n",
      "h.7.attn.c_attn.weight torch.Size([768, 2304])\n",
      "h.7.attn.c_attn.bias torch.Size([2304])\n",
      "h.7.attn.c_proj.weight torch.Size([768, 768])\n",
      "h.7.attn.c_proj.bias torch.Size([768])\n",
      "h.7.ln_2.weight torch.Size([768])\n",
      "h.7.ln_2.bias torch.Size([768])\n",
      "h.7.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "h.7.mlp.c_fc.bias torch.Size([3072])\n",
      "h.7.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "h.7.mlp.c_proj.bias torch.Size([768])\n",
      "h.8.ln_1.weight torch.Size([768])\n",
      "h.8.ln_1.bias torch.Size([768])\n",
      "h.8.attn.bias torch.Size([1, 1, 1024, 1024])\n",
      "h.8.attn.c_attn.weight torch.Size([768, 2304])\n",
      "h.8.attn.c_attn.bias torch.Size([2304])\n",
      "h.8.attn.c_proj.weight torch.Size([768, 768])\n",
      "h.8.attn.c_proj.bias torch.Size([768])\n",
      "h.8.ln_2.weight torch.Size([768])\n",
      "h.8.ln_2.bias torch.Size([768])\n",
      "h.8.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "h.8.mlp.c_fc.bias torch.Size([3072])\n",
      "h.8.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "h.8.mlp.c_proj.bias torch.Size([768])\n",
      "h.9.ln_1.weight torch.Size([768])\n",
      "h.9.ln_1.bias torch.Size([768])\n",
      "h.9.attn.bias torch.Size([1, 1, 1024, 1024])\n",
      "h.9.attn.c_attn.weight torch.Size([768, 2304])\n",
      "h.9.attn.c_attn.bias torch.Size([2304])\n",
      "h.9.attn.c_proj.weight torch.Size([768, 768])\n",
      "h.9.attn.c_proj.bias torch.Size([768])\n",
      "h.9.ln_2.weight torch.Size([768])\n",
      "h.9.ln_2.bias torch.Size([768])\n",
      "h.9.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "h.9.mlp.c_fc.bias torch.Size([3072])\n",
      "h.9.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "h.9.mlp.c_proj.bias torch.Size([768])\n",
      "h.10.ln_1.weight torch.Size([768])\n",
      "h.10.ln_1.bias torch.Size([768])\n",
      "h.10.attn.bias torch.Size([1, 1, 1024, 1024])\n",
      "h.10.attn.c_attn.weight torch.Size([768, 2304])\n",
      "h.10.attn.c_attn.bias torch.Size([2304])\n",
      "h.10.attn.c_proj.weight torch.Size([768, 768])\n",
      "h.10.attn.c_proj.bias torch.Size([768])\n",
      "h.10.ln_2.weight torch.Size([768])\n",
      "h.10.ln_2.bias torch.Size([768])\n",
      "h.10.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "h.10.mlp.c_fc.bias torch.Size([3072])\n",
      "h.10.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "h.10.mlp.c_proj.bias torch.Size([768])\n",
      "h.11.ln_1.weight torch.Size([768])\n",
      "h.11.ln_1.bias torch.Size([768])\n",
      "h.11.attn.bias torch.Size([1, 1, 1024, 1024])\n",
      "h.11.attn.c_attn.weight torch.Size([768, 2304])\n",
      "h.11.attn.c_attn.bias torch.Size([2304])\n",
      "h.11.attn.c_proj.weight torch.Size([768, 768])\n",
      "h.11.attn.c_proj.bias torch.Size([768])\n",
      "h.11.ln_2.weight torch.Size([768])\n",
      "h.11.ln_2.bias torch.Size([768])\n",
      "h.11.mlp.c_fc.weight torch.Size([768, 3072])\n",
      "h.11.mlp.c_fc.bias torch.Size([3072])\n",
      "h.11.mlp.c_proj.weight torch.Size([3072, 768])\n",
      "h.11.mlp.c_proj.bias torch.Size([768])\n",
      "ln_f.weight torch.Size([768])\n",
      "ln_f.bias torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "for i in data.keys():\n",
    "    print(i, data[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x717bd92ff640>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot wpe.weight\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "wpe = data['wpe.weight'].numpy()\n",
    "\n",
    "plt.imshow(wpe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768, 768])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['h.0.attn.c_proj.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 768) (768, 768) (768, 768) torch.Size([768, 2304])\n",
      "(768,) (768,) (768,) torch.Size([2304])\n",
      "(768, 768) (768, 768) (768, 768) torch.Size([768, 2304])\n",
      "(768,) (768,) (768,) torch.Size([2304])\n",
      "(768, 768) (768, 768) (768, 768) torch.Size([768, 2304])\n",
      "(768,) (768,) (768,) torch.Size([2304])\n",
      "(768, 768) (768, 768) (768, 768) torch.Size([768, 2304])\n",
      "(768,) (768,) (768,) torch.Size([2304])\n",
      "(768, 768) (768, 768) (768, 768) torch.Size([768, 2304])\n",
      "(768,) (768,) (768,) torch.Size([2304])\n",
      "(768, 768) (768, 768) (768, 768) torch.Size([768, 2304])\n",
      "(768,) (768,) (768,) torch.Size([2304])\n",
      "(768, 768) (768, 768) (768, 768) torch.Size([768, 2304])\n",
      "(768,) (768,) (768,) torch.Size([2304])\n",
      "(768, 768) (768, 768) (768, 768) torch.Size([768, 2304])\n",
      "(768,) (768,) (768,) torch.Size([2304])\n",
      "(768, 768) (768, 768) (768, 768) torch.Size([768, 2304])\n",
      "(768,) (768,) (768,) torch.Size([2304])\n",
      "(768, 768) (768, 768) (768, 768) torch.Size([768, 2304])\n",
      "(768,) (768,) (768,) torch.Size([2304])\n",
      "(768, 768) (768, 768) (768, 768) torch.Size([768, 2304])\n",
      "(768,) (768,) (768,) torch.Size([2304])\n",
      "(768, 768) (768, 768) (768, 768) torch.Size([768, 2304])\n",
      "(768,) (768,) (768,) torch.Size([2304])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.makedirs(\"gpt_weights\", exist_ok=True)\n",
    "for key in data.keys():\n",
    "    if \"attn.c_attn\" in key:\n",
    "        # split to q, k, v\n",
    "        q, k, v = np.split(data[key].numpy(), 3, axis=-1)\n",
    "        print(q.shape, k.shape, v.shape, data[key].shape)\n",
    "        # q.tofile(f\"gpt_weights/{key}.q.bin\")\n",
    "        # k.tofile(f\"gpt_weights/{key}.k.bin\")\n",
    "        # v.tofile(f\"gpt_weights/{key}.v.bin\")\n",
    "    else:\n",
    "        pass\n",
    "        # data[key].numpy().tofile(f\"gpt_weights/{key}.bin\")\n",
    "        # print(data[key].numpy().shape)\n",
    "\n",
    "# save transpose of wte.weight as etw.weight\n",
    "\n",
    "etw = data['wte.weight'].numpy().T\n",
    "etw.tofile(\"gpt_weights/etw.weight.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Config {\n",
       "  \"_name_or_path\": \"gpt2\",\n",
       "  \"activation_function\": \"gelu_new\",\n",
       "  \"architectures\": [\n",
       "    \"GPT2LMHeadModel\"\n",
       "  ],\n",
       "  \"attn_pdrop\": 0.1,\n",
       "  \"bos_token_id\": 50256,\n",
       "  \"embd_pdrop\": 0.1,\n",
       "  \"eos_token_id\": 50256,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"layer_norm_epsilon\": 1e-05,\n",
       "  \"model_type\": \"gpt2\",\n",
       "  \"n_ctx\": 1024,\n",
       "  \"n_embd\": 768,\n",
       "  \"n_head\": 12,\n",
       "  \"n_inner\": null,\n",
       "  \"n_layer\": 12,\n",
       "  \"n_positions\": 1024,\n",
       "  \"reorder_and_upcast_attn\": false,\n",
       "  \"resid_pdrop\": 0.1,\n",
       "  \"scale_attn_by_inverse_layer_idx\": false,\n",
       "  \"scale_attn_weights\": true,\n",
       "  \"summary_activation\": null,\n",
       "  \"summary_first_dropout\": 0.1,\n",
       "  \"summary_proj_to_labels\": true,\n",
       "  \"summary_type\": \"cls_index\",\n",
       "  \"summary_use_proj\": true,\n",
       "  \"task_specific_params\": {\n",
       "    \"text-generation\": {\n",
       "      \"do_sample\": true,\n",
       "      \"max_length\": 50\n",
       "    }\n",
       "  },\n",
       "  \"transformers_version\": \"4.42.4\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50257\n",
       "}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config._attn_implementation = 'eager'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "# import model for text generation\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = AutoModelForCausalLM.from_pretrained('gpt2')\n",
    "# model = GPT2Model.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(' a',\n",
       " tensor(257),\n",
       " {'input_ids': tensor([[15496,    11,   616,  1438,   318,  1757,    13,   314,  1101]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Hello, my name is John. I'm\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "# print(encoded_input['input_ids'].shape)\n",
    "output = model(**encoded_input, output_hidden_states=True)\n",
    "tokenizer.decode(output.logits.argmax(2)[0][-1]), output.logits.argmax(2)[0][-1], encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "output['hidden_states'][0][0].detach().numpy().tofile(\"gpt_weights/input.bin\")\n",
    "output.logits[0].detach().numpy().tofile(\"gpt_weights/output.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[15496,    11,   616,  1438,   318,  1757,    13,   314,  1101,   257,\n",
       "           6260,    11,   290,   314,  1101,   257,  6260,    13,   314,  1101,\n",
       "            257,  6260,    13,   314,  1101,   257,  6260,    13,   314,  1101,\n",
       "            257,  6260,    13,   314,  1101,   257,  6260,    13,   314,  1101,\n",
       "            257,  6260,    13,   314,  1101,   257,  6260,    13,   314,  1101,\n",
       "            257,  6260,    13,   314,  1101,   257,  6260,    13,   314,  1101,\n",
       "            257,  6260,    13,   314,  1101,   257,  6260,    13,   314,  1101,\n",
       "            257,  6260,    13,   314,  1101,   257,  6260,    13,   314,  1101,\n",
       "            257,  6260,    13,   314,  1101,   257,  6260,    13,   314,  1101,\n",
       "            257,  6260,    13,   314,  1101,   257,  6260,    13,   314,  1101,\n",
       "            257,  6260,    13,   314,  1101,   257,  6260,    13,   314]]),\n",
       " \"Hello, my name is John. I'm a writer, and I'm a writer. I'm a writer. I'm a writer. I'm a writer. I'm a writer. I'm a writer. I'm a writer. I'm a writer. I'm a writer. I'm a writer. I'm a writer. I'm a writer. I'm a writer. I'm a writer. I'm a writer. I'm a writer. I'm a writer. I'm a writer. I'm a writer. I\")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model.generate(encoded_input['input_ids'], max_length=109, do_sample=False)\n",
    "out, tokenizer.decode(out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = [257, 6260, 11, 290, 314, 1101, 257, 6260, 13, 314, 1101, 257, 6260, 13, 314, 1101, 257, 6260, 13, 314, 1101, 257, 6260, 13, 314, 1101, 257, 6260, 13, 314, 1101, 257, 6260, 13, 314, 1101, 257, 6260, 13, 314, 1101, 257, 6260, 13, 314, 1101, 257, 6260, 13, 314, 1101, 257, 6260, 13, 314, 1101, 257, 6260, 13, 314, 1101, 257, 6260, 13, 314, 1101, 257, 6260, 13, 314, 1101, 257, 6260, 13, 314, 1101, 257, 6260, 13, 314, 1101, 257, 6260, 13, 314, 1101, 257, 6260, 13, 314, 1101, 257, 6260, 13, 314, 1101, 257, 6260, 13, 314]\n",
    "out2 = [257,\n",
    "           6260,    11,   290,   314,  1101,   257,  6260,    13,   314,  1101,\n",
    "            257,  6260,    13,   314,  1101,   257,  6260,    13,   314,  1101,\n",
    "            257,  6260,    13,   314,  1101,   257,  6260,    13,   314,  1101,\n",
    "            257,  6260,    13,   314,  1101,   257,  6260,    13,   314,  1101,\n",
    "            257,  6260,    13,   314,  1101,   257,  6260,    13,   314,  1101,\n",
    "            257,  6260,    13,   314,  1101,   257,  6260,    13,   314,  1101,\n",
    "            257,  6260,    13,   314,  1101,   257,  6260,    13,   314,  1101,\n",
    "            257,  6260,    13,   314,  1101,   257,  6260,    13,   314,  1101,\n",
    "            257,  6260,    13,   314,  1101,   257,  6260,    13,   314,  1101,\n",
    "            257,  6260,    13,   314,  1101,   257,  6260,    13,   314,  1101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out == out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(out)):\n",
    "    if out[i] != out2[i]:\n",
    "        print(i, out[i], out2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" a writer, and I'm a writer. I'm a writer. I'm a writer. I'm a writer.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([257,6260,11,290,314,1101,257,6260,13,314,1101,257,6260,13,314,1101,257,6260,13,314,1101,257,6260,13])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "misc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
